{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mData Processing Basics Notebook\u001b[0m\n",
      "Note: All the data-processing transformations must be applied to\u001b[1m training set only\u001b[0m though this notebook has applied it to complete dataset.\n",
      "Some transformations are required for test set too, eg: NaN value replacement, whereas some must strictly not be applied to test set, eg: featue scaling.\n"
     ]
    }
   ],
   "source": [
    "bold = '\\033[1m'\n",
    "cbold = '\\033[0m'\n",
    "print(bold+'Data Processing Basics Notebook'+cbold)\n",
    "print('Note: All the data-processing transformations must be applied to'+bold+' training set only'+cbold+' though this notebook has applied it to complete dataset.')\n",
    "print('Some transformations are required for test set too, eg: NaN value replacement, whereas some must strictly not be applied to test set, eg: featue scaling.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of dataset:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "path = '/home/ubuntu/IntroToML/housing.csv'\n",
    "path2 = '/home/ubuntu/Machine-Learning-Algorithms/titanic_test.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "print('Preview of dataset:\\n')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some general analysis of dataset: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "********************************************************************************\n",
      "\n",
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Some general analysis of dataset: \\n\")\n",
    "print(dataset.info())\n",
    "print('********************************************************************************\\n')\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mData Cleaning(Numerical data)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(bold+\"Data Cleaning(Numerical data)\"+cbold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dropna() to drop samples with NaN:\n",
      "Dummy dataset size before dropna(): (20640, 10)\n",
      "Dummy dataset size after dropna(): (20433, 10)\n",
      "Dummy dataset size before dropna(): (20640, 10)\n",
      "\n",
      "\n",
      "Dummy dataset size before dropna(): (20640, 10)\n",
      "Dummy dataset size after dropna(): (20640, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Using dropna() to drop samples with NaN:')\n",
    "print('Dummy dataset size before dropna():', dataset.shape)\n",
    "dataset.dropna(inplace=True,how='any')#drops all the samples with atleast one NaN value\n",
    "print('Dummy dataset size after dropna():', dataset.shape)\n",
    "\n",
    "dataset = pd.read_csv(path)#reloading the data\n",
    "print('Dummy dataset size before dropna():', dataset.shape)\n",
    "dataset.dropna(inplace=True,how='all')#drops all the samples with all values as NaN\n",
    "print('\\n\\nDummy dataset size before dropna():', dataset.shape)\n",
    "print('Dummy dataset size after dropna():', dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using drop() to drop features and samples:\n",
      "\n",
      "Dropping features:\n",
      "\n",
      "Colunms before drop():\n",
      " Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'median_house_value', 'ocean_proximity'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns after drop():\n",
      " Index(['longitude', 'latitude', 'housing_median_age', 'total_bedrooms',\n",
      "       'population', 'households', 'median_income', 'median_house_value'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Dropping samples:\n",
      "\n",
      "Samples before drop():\n",
      "     latitude  housing_median_age  total_rooms\n",
      "0     37.88                41.0        880.0\n",
      "1     37.86                21.0       7099.0\n",
      "2     37.85                52.0       1467.0\n",
      "3     37.85                52.0       1274.0\n",
      "4     37.85                52.0       1627.0\n",
      "\n",
      "Samples after drop():\n",
      "    latitude  housing_median_age  total_rooms\n",
      "0     37.88                41.0        880.0\n",
      "4     37.85                52.0       1627.0\n",
      "5     37.85                52.0        919.0\n",
      "6     37.84                52.0       2535.0\n",
      "7     37.84                52.0       3104.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using drop() to drop features and samples:\")\n",
    "print('\\nDropping features:\\n')\n",
    "dataset = pd.read_csv(path)\n",
    "print(\"Colunms before drop():\\n\",dataset.columns)\n",
    "dataset.drop(['total_rooms','ocean_proximity'],inplace=True,axis=1)#drops off the columns passed as subset parameter\n",
    "#axis=1 indicates that the elements to be dropped are columns\n",
    "print(\"\\nColumns after drop():\\n\",dataset.columns)\n",
    "\n",
    "print(\"\\n\\nDropping samples:\")\n",
    "dataset = pd.read_csv(path)\n",
    "print(\"\\nSamples before drop():\\n \",dataset.iloc[0:5,1:4])\n",
    "dataset.drop([1,2,3],inplace=True)#drops off the given samples i.e. sample 1,2 and 3\n",
    "print(\"\\nSamples after drop():\\n\",dataset.iloc[0:5,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing NaN with a constant value:\n",
      "Columns containing NaN values before fillna():  ['total_bedrooms']\n",
      "Columns containing NaN values after fillna():  []\n",
      "\n",
      "\n",
      "Replacing NaN with the mean:\n",
      "Columns containing NaN values before fillna():  ['total_bedrooms']\n",
      "Columns containing NaN values after fillna():  []\n",
      "\n",
      "\n",
      "Using methods of fillna like method=(ffill/bfill/etc)\n",
      "Columns containing NaN values before fillna():  ['total_bedrooms']\n",
      "Columns containing NaN values after fillna():  []\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(path)\n",
    "print('Replacing NaN with a constant value:')\n",
    "print(\"Columns containing NaN values before fillna(): \",dataset.columns[dataset.isnull().any()].tolist())\n",
    "dataset.fillna(0,inplace=True)#replacing all Nan values with a constant value 0\n",
    "print(\"Columns containing NaN values after fillna(): \",dataset.columns[dataset.isnull().any()].tolist())\n",
    "\n",
    "dataset = pd.read_csv(path)\n",
    "print('\\n\\nReplacing NaN with the mean:')\n",
    "print(\"Columns containing NaN values before fillna(): \",dataset.columns[dataset.isnull().any()].tolist())\n",
    "dataset.fillna({\n",
    "    'total_bedrooms':dataset['total_bedrooms'].mean()#replaces the NaN with mean value\n",
    "},inplace=True)\n",
    "print(\"Columns containing NaN values after fillna(): \",dataset.columns[dataset.isnull().any()].tolist())\n",
    "\n",
    "dataset = pd.read_csv(path)\n",
    "print('\\n\\nUsing methods of fillna like method=(ffill/bfill/etc)')\n",
    "print(\"Columns containing NaN values before fillna(): \",dataset.columns[dataset.isnull().any()].tolist())\n",
    "dataset.fillna(method='ffill',inplace=True)#using method parameter of filllna\n",
    "print(\"Columns containing NaN values after fillna(): \",dataset.columns[dataset.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Imputer to handle NaN values: \n",
      "Columns with NaN values before imputation:  ['total_bedrooms']\n",
      "Columns with Nan after imputation:  []\n",
      "\n",
      "\n",
      "Using Imputer with another dataset: \n",
      "Dataset before imputation: \n",
      "    PassengerId  Pclass   Age  SibSp  Parch      Fare\n",
      "20          912       1  55.0      1      0   59.4000\n",
      "21          913       3   9.0      0      1    3.1708\n",
      "22          914       1   NaN      0      0   31.6833\n",
      "23          915       1  21.0      0      1   61.3792\n",
      "24          916       1  48.0      1      3  262.3750\n",
      "25          917       3  50.0      1      0   14.5000\n",
      "26          918       1  22.0      0      1   61.9792\n",
      "27          919       3  22.5      0      0    7.2250\n",
      "28          920       1  41.0      0      0   30.5000\n",
      "29          921       3   NaN      2      0   21.6792\n",
      "\n",
      "Dataset after imputation:\n",
      "     PassengerId  Pclass    Age  SibSp  Parch      Fare\n",
      "20        912.0     1.0   55.0    1.0    0.0   59.4000\n",
      "21        913.0     3.0    9.0    0.0    1.0    3.1708\n",
      "22        914.0     1.0  999.9    0.0    0.0   31.6833\n",
      "23        915.0     1.0   21.0    0.0    1.0   61.3792\n",
      "24        916.0     1.0   48.0    1.0    3.0  262.3750\n",
      "25        917.0     3.0   50.0    1.0    0.0   14.5000\n",
      "26        918.0     1.0   22.0    0.0    1.0   61.9792\n",
      "27        919.0     3.0   22.5    0.0    0.0    7.2250\n",
      "28        920.0     1.0   41.0    0.0    0.0   30.5000\n",
      "29        921.0     3.0  999.9    2.0    0.0   21.6792\n"
     ]
    }
   ],
   "source": [
    "print('Using Imputer to handle NaN values: ')\n",
    "\n",
    "dataset = pd.read_csv(path)\n",
    "dataset.drop('ocean_proximity',axis=1,inplace=True)#dropping non-numerical features\n",
    "\n",
    "print('Columns with NaN values before imputation: ',dataset.columns[dataset.isnull().any()].tolist())\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "temp = imputer.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(temp,columns=dataset.columns)\n",
    "\n",
    "print(\"Columns with Nan after imputation: \",dataset.columns[dataset.isnull().any()].tolist())\n",
    "\n",
    "print('\\n\\nUsing Imputer with another dataset: ')\n",
    "dataset = pd.read_csv(path2)\n",
    "dataset.drop(['Name','Sex','Ticket','Cabin','Embarked'],axis=1,inplace=True)\n",
    "print('Dataset before imputation: ')\n",
    "print(dataset[20:30])\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='constant',fill_value=999.9)\n",
    "temp = imputer.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(temp,columns=dataset.columns)\n",
    "print('\\nDataset after imputation:\\n',dataset[20:30])\n",
    "#values for strategy='mean/median/most_frequent/constant' if strategy=='constant' then fill_value=somevalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHandling text and Categorical attributes:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(bold+\"Handling text and Categorical attributes:\"+cbold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of data:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "\n",
      "Using LabelEncoder class to convert string categorical data to integer values:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value  ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0                3  \n",
      "1      2401.0      1138.0         8.3014            358500.0                3  \n",
      "2       496.0       177.0         7.2574            352100.0                3  \n",
      "3       558.0       219.0         5.6431            341300.0                3  \n",
      "4       565.0       259.0         3.8462            342200.0                3  \n",
      "\n",
      "\n",
      "Using OneHotEncoder class to convert the integer categorical data into multiple binary-valued features called one-hot vectors:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value  op1  op2  op3  \\\n",
      "0       322.0       126.0         8.3252            452600.0  0.0  0.0  0.0   \n",
      "1      2401.0      1138.0         8.3014            358500.0  0.0  0.0  0.0   \n",
      "2       496.0       177.0         7.2574            352100.0  0.0  0.0  0.0   \n",
      "3       558.0       219.0         5.6431            341300.0  0.0  0.0  0.0   \n",
      "4       565.0       259.0         3.8462            342200.0  0.0  0.0  0.0   \n",
      "\n",
      "   op4  op5  \n",
      "0  1.0  0.0  \n",
      "1  1.0  0.0  \n",
      "2  1.0  0.0  \n",
      "3  1.0  0.0  \n",
      "4  1.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(path)\n",
    "print('Preview of data:\\n')\n",
    "print(dataset.head())\n",
    "\n",
    "print('\\n\\nUsing LabelEncoder class to convert string categorical data to integer values:\\n')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "temp = encoder.fit_transform(dataset['ocean_proximity'])\n",
    "\n",
    "dataset.drop(['ocean_proximity'],axis=1,inplace=True)#dropping the previous categorical feature ocean_proximity\n",
    "dataset['ocean_proximity'] = temp #appending the new integer based categorical feature\n",
    "print(dataset.head())\n",
    "\n",
    "print('\\n\\nUsing OneHotEncoder class to convert the integer categorical data into multiple binary-valued features called one-hot vectors:\\n')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "#fit_transform of OneHotEncoder requires 2D array, thus we use reshape on the dataset['ocean_proximity'] to obtain 2D array feature\n",
    "temp = encoder.fit_transform(dataset['ocean_proximity'].values.reshape(-1,1))\n",
    "temp = temp.toarray()#temp is a scipy sparse matrix and thus we converted it into 2D matrix form\n",
    "dataset.drop('ocean_proximity',axis=1,inplace=True)#dropping previous ocean_proximity feature\n",
    "dataset['op1'] = temp[:,0]#adding the one hot encoder vectors to the dataset\n",
    "dataset['op2'] = temp[:,1]\n",
    "dataset['op3'] = temp[:,2]\n",
    "dataset['op4'] = temp[:,3]\n",
    "dataset['op5'] = temp[:,4]\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of data:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Using LabelBinarizer class to convert string categorial data into integer and subsequently into one-hot vectors.\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value  op1  op2  op3  \\\n",
      "0       322.0       126.0         8.3252            452600.0    0    0    0   \n",
      "1      2401.0      1138.0         8.3014            358500.0    0    0    0   \n",
      "2       496.0       177.0         7.2574            352100.0    0    0    0   \n",
      "3       558.0       219.0         5.6431            341300.0    0    0    0   \n",
      "4       565.0       259.0         3.8462            342200.0    0    0    0   \n",
      "\n",
      "   op4  op5  \n",
      "0    1    0  \n",
      "1    1    0  \n",
      "2    1    0  \n",
      "3    1    0  \n",
      "4    1    0  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(path)\n",
    "print('Preview of data:\\n')\n",
    "print(dataset.head())\n",
    "print('\\nUsing LabelBinarizer class to convert string categorial data into integer and subsequently into one-hot vectors.\\n')\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "#fit_transform of LabelBinarizer requires 2D array, thus we use reshape on the dataset['ocean_proximity'] to obtain 2D array feature\n",
    "temp = encoder.fit_transform(dataset['ocean_proximity'].values.reshape(-1,1))\n",
    "#temp is an np.array object and is a 2D matrix thus we do not have to use toarray() as we did in the previous case\n",
    "dataset.drop(['ocean_proximity'],axis=1,inplace=True)#dropping previous ocean_proximity feature\n",
    "dataset['op1'] = temp[:,0]#adding the one hot encoder vectors to the dataset\n",
    "dataset['op2'] = temp[:,1]\n",
    "dataset['op3'] = temp[:,2]\n",
    "dataset['op4'] = temp[:,3]\n",
    "dataset['op5'] = temp[:,4]\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCustom Transformers:\u001b[0m\n",
      "\n",
      "Preview of the dataset:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Features added:\n",
      " Bedrooms per room\n",
      " Rooms per household\n",
      " Population per household\n",
      "\n",
      "\n",
      "Preview of dataset after adding new feature;\n",
      "\n",
      "        0      1   2     3     4     5     6       7       8         9  \\\n",
      "0 -122.23  37.88  41   880   129   322   126  8.3252  452600  NEAR BAY   \n",
      "1 -122.22  37.86  21  7099  1106  2401  1138  8.3014  358500  NEAR BAY   \n",
      "2 -122.24  37.85  52  1467   190   496   177  7.2574  352100  NEAR BAY   \n",
      "3 -122.25  37.85  52  1274   235   558   219  5.6431  341300  NEAR BAY   \n",
      "4 -122.25  37.85  52  1627   280   565   259  3.8462  342200  NEAR BAY   \n",
      "\n",
      "         10       11       12  \n",
      "0  0.146591  6.98413  2.55556  \n",
      "1  0.155797  6.23814  2.10984  \n",
      "2  0.129516  8.28814  2.80226  \n",
      "3  0.184458  5.81735  2.54795  \n",
      "4  0.172096  6.28185  2.18147  \n"
     ]
    }
   ],
   "source": [
    "print(bold+'Custom Transformers:'+cbold)\n",
    "dataset = pd.read_csv(path)\n",
    "print('\\nPreview of the dataset:\\n')\n",
    "print(dataset.head())\n",
    "\n",
    "#custom transformer\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "\n",
    "rooms,bedrooms,population,households = 3,4,5,6\n",
    "\n",
    "class AttributeAdder(BaseEstimator,TransformerMixin): #Custom transformer\n",
    "    def __init__(self,bedrooms_room=True,rooms_household=True,population_household=True):\n",
    "        self.bedrooms_room = bedrooms_room\n",
    "        self.rooms_household = rooms_household\n",
    "        self.population_household = population_household\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        print('\\nFeatures added:')\n",
    "        if self.bedrooms_room:#if true add feature bedrooms_per_room\n",
    "            X = np.c_[X,X[:,bedrooms]/X[:,rooms]]\n",
    "            print(' Bedrooms per room')    \n",
    "                \n",
    "        if self.rooms_household:#if true add feature rooms_per_household\n",
    "            X = np.c_[X,X[:,rooms]/X[:,households]]\n",
    "            print(' Rooms per household')\n",
    "            \n",
    "        if self.population_household:#if true add feature population_per_household\n",
    "            X = np.c_[X,X[:,population]/X[:,households]]\n",
    "            print(' Population per household')\n",
    "        print('\\n')\n",
    "        return X\n",
    "    \n",
    "adder = AttributeAdder()#constructor provides 3 hyperparameters, we can use any or all\n",
    "temp = adder.fit_transform(dataset.values)#it calls both fit() as well as transform(). This can be done because we inherited some classes\n",
    "dataset = pd.DataFrame(temp)\n",
    "print('Preview of dataset after adding new feature;\\n')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFeature Scaling:\u001b[0m\n",
      "Preview of dataset:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "\n",
      "Dataset after MinMax scaling:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0   0.211155  0.567481            0.784314     0.022331        0.019863   \n",
      "1   0.212151  0.565356            0.392157     0.180503        0.171477   \n",
      "2   0.210159  0.564293            1.000000     0.037260        0.029330   \n",
      "3   0.209163  0.564293            1.000000     0.032352        0.036313   \n",
      "4   0.209163  0.564293            1.000000     0.041330        0.043296   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0    0.008941    0.020556       0.539668            0.902266        NEAR BAY  \n",
      "1    0.067210    0.186976       0.538027            0.708247        NEAR BAY  \n",
      "2    0.013818    0.028943       0.466028            0.695051        NEAR BAY  \n",
      "3    0.015555    0.035849       0.354699            0.672783        NEAR BAY  \n",
      "4    0.015752    0.042427       0.230776            0.674638        NEAR BAY  \n",
      "\n",
      "\n",
      "Dataset after Standard scaling:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0  -1.327835  1.052548            0.982143    -0.804819       -0.970325   \n",
      "1  -1.322844  1.043185           -0.607019     2.045890        1.348276   \n",
      "2  -1.332827  1.038503            1.856182    -0.535746       -0.825561   \n",
      "3  -1.337818  1.038503            1.856182    -0.624215       -0.718768   \n",
      "4  -1.337818  1.038503            1.856182    -0.462404       -0.611974   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0   -0.974429   -0.977033       2.344766            2.129631        NEAR BAY  \n",
      "1    0.861439    1.669961       2.332238            1.314156        NEAR BAY  \n",
      "2   -0.820777   -0.843637       1.782699            1.258693        NEAR BAY  \n",
      "3   -0.766028   -0.733781       0.932968            1.165100        NEAR BAY  \n",
      "4   -0.759847   -0.629157      -0.012881            1.172900        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "print(bold+'Feature Scaling:'+cbold)\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "print('Preview of dataset:\\n')\n",
    "print(dataset.head())\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "op = dataset['ocean_proximity']\n",
    "dataset.drop(['ocean_proximity'],axis=1,inplace=True)#MinMaxScaler cannot operate on non-numerical values\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "temp = scaler.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(temp,columns=dataset.columns)\n",
    "dataset['ocean_proximity'] = op#adding the dropped feature\n",
    "print('\\n\\nDataset after MinMax scaling:\\n')\n",
    "print(dataset.head())\n",
    "\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "op = dataset['ocean_proximity']\n",
    "dataset.drop(['ocean_proximity'],axis=1,inplace=True)#StandardScaler cannot operate on non-numerical values\n",
    "scaler = StandardScaler()\n",
    "temp = scaler.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(temp,columns=dataset.columns)\n",
    "dataset['ocean_proximity'] = op#adding the dropped feature\n",
    "print('\\n\\nDataset after Standard scaling:\\n')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTransformation Pipeline:\u001b[0m\n",
      "Preview of data:\n",
      "\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Features added:\n",
      " Bedrooms per room\n",
      " Rooms per household\n",
      " Population per household\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "After data-processing pipeline:\n",
      "\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0 -1.327835  1.052548  0.982143 -0.804819 -0.972476 -0.974429 -0.977033   \n",
      "1 -1.322844  1.043185 -0.607019  2.045890  1.357143  0.861439  1.669961   \n",
      "2 -1.332827  1.038503  1.856182 -0.535746 -0.827024 -0.820777 -0.843637   \n",
      "3 -1.337818  1.038503  1.856182 -0.624215 -0.719723 -0.766028 -0.733781   \n",
      "4 -1.337818  1.038503  1.856182 -0.462404 -0.612423 -0.759847 -0.629157   \n",
      "\n",
      "          7         8         9        10        11   12   13   14   15   16  \n",
      "0  2.344766  2.129631 -1.029988  0.628559 -0.049597  0.0  0.0  0.0  1.0  0.0  \n",
      "1  2.332238  1.314156 -0.888897  0.327041 -0.092512  0.0  0.0  0.0  1.0  0.0  \n",
      "2  1.782699  1.258693 -1.291686  1.155620 -0.025843  0.0  0.0  0.0  1.0  0.0  \n",
      "3  0.932968  1.165100 -0.449613  0.156966 -0.050329  0.0  0.0  0.0  1.0  0.0  \n",
      "4 -0.012881  1.172900 -0.639087  0.344711 -0.085616  0.0  0.0  0.0  1.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "print(bold+'Transformation Pipeline:'+cbold)\n",
    "#Pipeling allows us to perform mutiple transformation in one go. Thus here we will combine all the transformation we have seen till now.\n",
    "\n",
    "dataset = pd.read_csv(path)\n",
    "print('Preview of data:\\n')\n",
    "print(dataset.head())\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "\n",
    "#In this case, transformations can be applied to numerical values and string values seperately\n",
    "#Through this transformer class we could select the type of features to which transformation is to be applied\n",
    "class AttributeSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attr):\n",
    "        self.attr = attr\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "            X.drop(self.attr,axis=1,inplace=True)    \n",
    "            return X\n",
    "\n",
    "#The transformer class below is used to add the deleted category feature 'ocean_proximity' back to the dataset\n",
    "#The number pipeline will be executed first, which would produce a dataframe with only numeric features, which is passed to category pipeline\n",
    "#Thus, before category pipeline proecesses it, we use this class to add the category based feature 'ocean_proximity' to dataframe\n",
    "class AppendingCatData(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attr):\n",
    "        self.attr = attr\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X['ocean_proximity'] = self.attr\n",
    "        return X    \n",
    "        \n",
    "        \n",
    "#Pipeline for numerical features\n",
    "numpipeline = Pipeline([\n",
    "    ('selector',AttributeSelector(dataset.columns[(dataset.dtypes.values != np.dtype('float64'))])),#returns the titles of all the columns those do not have float64 type values\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('attri_adder',AttributeAdder()),\n",
    "    ('scaling',StandardScaler()),    \n",
    "]) \n",
    "\n",
    "#pipeline for categorical features(most probably string/character features)\n",
    "catpipeline = Pipeline([    \n",
    "    ('appendingCatAttr',AppendingCatData(dataset['ocean_proximity'])),\n",
    "    ('selector',AttributeSelector(dataset.columns[(dataset.dtypes.values != np.dtype('object'))])),\n",
    "    ('one_hot_encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "combinedpipeline = FeatureUnion(transformer_list=[  #Combining the pipeline for nummeric and non-numeric features\n",
    "    ('number_pipeline',numpipeline),\n",
    "    ('category_pipeline',catpipeline)\n",
    "])\n",
    "temp = combinedpipeline.fit_transform(dataset) #calling the combined pipeline to processes the complete data at once\n",
    "dataset = pd.DataFrame(temp)\n",
    "print('\\n\\nAfter data-processing pipeline:\\n')\n",
    "print(dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
